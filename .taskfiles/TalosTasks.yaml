# yaml-language-server: $schema=https://taskfile.dev/schema.json
---
version: '3'

vars:
  TALOS_DIR: '{{ .REPOSITORY_DIR }}/talos-linux'
  CLUSTER_API_SERVER_PORT: '{{ .CLUSTER_API_SERVER_PORT | default 6443 }}'

  # renovate: registryUrl=https://helm.cilium.io/ chart=cilium
  CILIUM_VERSION: '{{ .CILIUM_VERSION | default "v1.14.0-snapshot.2" }}'

tasks:

  generate-secrets-bundle-from-pki-output-folder:
    desc: Generate a secrets bundle for a Talos environment using pre-generated Single Root CA PKI directory.
    vars:
      ORGANIZATION_NAME: '{{ .ORGANIZATION_NAME }}'
      CLUSTER_NAME: '{{ .CLUSTER_NAME }}'
      K8S_PKI_DIR: '{{ .K8S_PKI_DIR }}'
      _CLEAN_ORG_NAME: '{{ .ORGANIZATION_NAME | lower | replace "(" "" | replace ")" "" | replace " " "-" | replace "." "" }}'
      _CLUSTER_DIR: '{{ .TALOS_DIR }}/{{ .CLUSTER_NAME }}-cluster'
      _SECRETS_BUNDLE_FILENAME: '{{ ._CLUSTER_DIR }}/secrets-bundle.yaml'
      _BOOTSTRAP_TOKEN:
        sh: kubeadm token generate
    preconditions:
      - sh: test '{{ .ORGANIZATION_NAME }}'
        msg: 'Please provide a valid ORGANIZATION_NAME'
      - sh: test '{{ ._BOOTSTRAP_TOKEN }}'
        msg: 'Issues using kubeadm to generate a bootstrap token _BOOTSTRAP_TOKEN'
      - sh: test '{{ .CLUSTER_NAME }}'
        msg: 'Please provide a valid CLUSTER_NAME'
      - sh: test '{{ .K8S_PKI_DIR }}'
        msg: 'Please provide a valid K8S_PKI_DIR'
      - sh: test -d {{ .K8S_PKI_DIR }}
        msg: 'Please provide a valid K8S_PKI_DIR {{ .K8S_PKI_DIR }}'
    cmds:
      - task: :_core:ensure-directory-exists
        vars: { DIRECTORY: '{{ ._SECRETS_BUNDLE_FILENAME | dir }}' }
      - talosctl gen secrets --from-kubernetes-pki "{{ .K8S_PKI_DIR }}" --kubernetes-bootstrap-token {{ ._BOOTSTRAP_TOKEN }} --output-file "{{ ._SECRETS_BUNDLE_FILENAME }}"
    sources:
      - '{{ .K8S_PKI_DIR }}'
    generates:
      - '{{ ._SECRETS_BUNDLE_FILENAME }}'

  generate-machine-templates:
    desc: Generate Machine Templates for a particular cluster
    vars:
      CLUSTER_NAME: "{{ .CLUSTER_NAME }}"
      CLUSTER_LOAD_BALANCER_IP: "{{ .CLUSTER_LOAD_BALANCER_IP }}"
      _CLUSTER_DIR: "{{ .TALOS_DIR }}/{{ .CLUSTER_NAME }}-cluster"
      _SECRETS_BUNDLE_FILENAME: "{{ ._CLUSTER_DIR }}/secrets-bundle.yaml"
      _MACHINE_TEMPLATES_DIR: "{{ ._CLUSTER_DIR }}/machine-templates"
      _CONTROL_PLANE_HOSTNAME: "control-plane"
    preconditions:
      - test {{ .CLUSTER_NAME }}
      - test {{ .CLUSTER_LOAD_BALANCER_IP }}
      - test -d {{ ._CLUSTER_DIR }}
      - test -f {{ ._SECRETS_BUNDLE_FILENAME }}
    cmds:
      - |
        talosctl gen config {{ .CLUSTER_NAME }}-cluster https://{{ ._CONTROL_PLANE_HOSTNAME }}.{{ .CLUSTER_DOMAIN }}:{{ .CLUSTER_API_SERVER_PORT }} \
          --with-secrets {{ ._SECRETS_BUNDLE_FILENAME }} \
          --additional-sans {{ ._CONTROL_PLANE_HOSTNAME }},{{ .CLUSTER_LOAD_BALANCER_IP }} \
          --dns-domain staging.lesmerises.jgarfield.com \
          --install-image ghcr.io/siderolabs/installer:v1.4.0 \
          --kubernetes-version 1.27.1 \
          --registry-mirror docker.io=http://pull-through-cache.lesmerises.jgarfield.com:5003,gcr.io=http://pull-through-cache.lesmerises.jgarfield.com:5001,ghcr.io=http://pull-through-cache.lesmerises.jgarfield.com:5000,registry.k8s.io=http://pull-through-cache.lesmerises.jgarfield.com:5002 \
          --talos-version v1.4.0 \
          --version v1alpha1 \
          --with-cluster-discovery=false \
          --with-docs=false \
          --with-examples=false \
          --config-patch='[{"op": "remove", "path": "/machine/certSANs"}]' \
          --config-patch @{{ ._CLUSTER_DIR }}/machine-patches/all-nodes.patch \
          --output {{ ._MACHINE_TEMPLATES_DIR }}
      - mv {{ ._MACHINE_TEMPLATES_DIR }}/talosconfig {{ ._CLUSTER_DIR }}

  generate-machine-config:
    internal: true
    desc: Generate Machine Configs for a particular cluster
    vars:
      CLUSTER_NAME: "{{.CLUSTER_NAME}}"
      CLUSTER_DIR: "{{.TALOS_DIR}}/{{.CLUSTER_NAME}}-cluster"
      NODE_TYPE: "{{.NODE_TYPE}}"
      NODE_NAME: "{{.NODE_NAME}}"
    cmds:
      - |
        talosctl machineconfig patch {{.CLUSTER_DIR}}/machine-templates/{{.NODE_TYPE}}.yaml \
          --patch @{{.CLUSTER_DIR}}/machine-patches/{{.NODE_NAME}}.patch \
          --output {{.CLUSTER_DIR}}/machine-configs/{{.NODE_NAME}}.yaml

  apply-machine-config:
    internal: true
    desc: Apply a Machine Config to a particular cluster node
    vars:
      CLUSTER_NAME: "{{.CLUSTER_NAME}}"
      NODE_NAME: "{{.NODE_NAME}}"
      CLUSTER_DIR: "{{.TALOS_DIR}}/{{.CLUSTER_NAME}}-cluster"
    cmds:
      - talosctl apply-config --insecure --nodes {{.NODE_NAME}}.{{.CLUSTER_DOMAIN}} --file {{.CLUSTER_DIR}}/machine-configs/{{.NODE_NAME}}.yaml

  bootstrap-etcd:
    internal: true
    desc: Bootstraps etcd on a particular cluster's '-cp01' node
    vars:
      CLUSTER_NAME: "{{.CLUSTER_NAME}}"
    cmds:
      - talosctl bootstrap --nodes k8s-cp01.{{.CLUSTER_DOMAIN}}

  install-cilium-via-helm:
    internal: true
    desc: Installs the Cilium CNI for a particular cluster
    vars:
      CLUSTER_NAME: "{{.CLUSTER_NAME}}"
      CLUSTER_DIR: "{{.TALOS_DIR}}/{{.CLUSTER_NAME}}-cluster"
    cmds:
      - helm repo update
      - |
        helm template \
            cilium \
            cilium/cilium \
            --version {{ .CILIUM_VERSION }} \
            --namespace kube-system \
            --set ipam.mode=kubernetes \
            --set kubeProxyReplacement=strict \
            --set securityContext.capabilities.ciliumAgent="{CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}" \
            --set securityContext.capabilities.cleanCiliumState="{NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}" \
            --set cgroup.autoMount.enabled=false \
            --set cgroup.hostRoot=/sys/fs/cgroup \
            --set k8sServiceHost="control-plane.{{ .CLUSTER_DOMAIN }}" \
            --set k8sServicePort="{{ .CLUSTER_API_SERVER_PORT }}" > {{ .CLUSTER_DIR }}/cilium.yaml \
            --set bgpControlPlane.enabled=true \
            --set ingressController.enabled=true \
            --set ingressController.loadbalancerMode=shared \
            --set hubble.relay.enabled=true \
            --set hubble.ui.enabled=true \
            --set hubble.peerService.clusterDomain="{{ .CLUSTER_DOMAIN }}" \
            --set gatewayAPI.enabled=true

      - kubectl apply -f {{ .CLUSTER_DIR }}/cilium.yaml

  machine-shutdown:
    internal: true
    desc: Apply a Machine Config to a particular cluster node
    vars:
      CLUSTER_NAME: "{{.CLUSTER_NAME}}"
      NODE: "{{.NODE}}"
      NODE_NAME: "{{.NODE_NAME}}"
      CLUSTER_DIR: "{{.TALOS_DIR}}/{{.CLUSTER_NAME}}-cluster"
    cmds:
      - talosctl apply-config --insecure --nodes {{.NODE}} --file {{.CLUSTER_DIR}}/machine-configs/{{.NODE_NAME}}.yaml
